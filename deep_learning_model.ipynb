{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# A. Base line model"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "# import the required libraries\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n      <th>Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>61.89</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n      <td>40.27</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n      <td>41.05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n      <td>44.30</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n0   540.0                 0.0      0.0  162.0               2.5   \n1   540.0                 0.0      0.0  162.0               2.5   \n2   332.5               142.5      0.0  228.0               0.0   \n3   332.5               142.5      0.0  228.0               0.0   \n4   198.6               132.4      0.0  192.0               0.0   \n\n   Coarse Aggregate  Fine Aggregate  Age  Strength  \n0            1040.0           676.0   28     79.99  \n1            1055.0           676.0   28     61.89  \n2             932.0           594.0  270     40.27  \n3             932.0           594.0  365     41.05  \n4             978.4           825.5  360     44.30  "
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Loading the concrete data\ndata = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\ndata.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "# Splitting the data into features and target\nX = data[data.columns[data.columns != 'Strength']] # all columns except Strength \ny = data['Strength'] # Strength column"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "# no. of features columns = input shape\nn_cols = X.shape[1]"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "'''Building the model with 1 hidden layers containing 10 nodes with \nReLU activation and compile with adam optimizer and mean squared error loss function'''\nmodel = tf.keras.models.Sequential([\n        # 10 neuron hidden layer\n        tf.keras.layers.Dense(10, activation='relu',input_shape=(n_cols,)),\n        # Only 1 output neuron.\n        tf.keras.layers.Dense(1)\n    ])\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "#0 mean squared error is 549.144287109375\n#1 mean squared error is 136.66424560546875\n#2 mean squared error is 99.11436462402344\n#3 mean squared error is 99.34284973144531\n#4 mean squared error is 113.36961364746094\n#5 mean squared error is 117.33661651611328\n#6 mean squared error is 100.48281860351562\n#7 mean squared error is 127.06002044677734\n#8 mean squared error is 129.47813415527344\n#9 mean squared error is 106.9997329711914\n#10 mean squared error is 111.30514526367188\n#11 mean squared error is 113.25389099121094\n#12 mean squared error is 112.67878723144531\n#13 mean squared error is 103.37322235107422\n#14 mean squared error is 108.85252380371094\n#15 mean squared error is 106.38521575927734\n#16 mean squared error is 120.29869842529297\n#17 mean squared error is 118.88227081298828\n#18 mean squared error is 104.03933715820312\n#19 mean squared error is 114.67874908447266\n#20 mean squared error is 113.03777313232422\n#21 mean squared error is 101.07972717285156\n#22 mean squared error is 73.38603973388672\n#23 mean squared error is 71.22753143310547\n#24 mean squared error is 60.25092315673828\n#25 mean squared error is 55.50364685058594\n#26 mean squared error is 52.72979736328125\n#27 mean squared error is 51.5090217590332\n#28 mean squared error is 50.844173431396484\n#29 mean squared error is 66.47571563720703\n#30 mean squared error is 45.786476135253906\n#31 mean squared error is 47.14129638671875\n#32 mean squared error is 46.08018112182617\n#33 mean squared error is 60.97944641113281\n#34 mean squared error is 49.34770202636719\n#35 mean squared error is 52.55653381347656\n#36 mean squared error is 61.7443733215332\n#37 mean squared error is 48.29872131347656\n#38 mean squared error is 49.304603576660156\n#39 mean squared error is 56.87327575683594\n#40 mean squared error is 50.524070739746094\n#41 mean squared error is 50.85428237915039\n#42 mean squared error is 53.42235565185547\n#43 mean squared error is 47.00908279418945\n#44 mean squared error is 55.60184097290039\n#45 mean squared error is 95.56571960449219\n#46 mean squared error is 58.09282684326172\n#47 mean squared error is 55.44731521606445\n#48 mean squared error is 50.52200698852539\n#49 mean squared error is 60.14813995361328\n"
                }
            ],
            "source": "# Training the model with 70% of training data for 50 epochs\nmean_squared_errors = []\ni=0\nwhile i<50: \n    from sklearn.model_selection import train_test_split\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)\n\n    hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0)\n    # mean_squared_error = last value in the history\n    mean_squared_error = hist.history['val_loss'][-1]\n    mean_squared_errors.append(mean_squared_error)\n    print(f\"#{i+1} mean squared error is {mean_squared_errors[i]}\")\n    i+=1"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Mean of mean_squared_error 53.849550552368164\nStandard Deviation of mean_squared_error 19.144246150522008\n"
                }
            ],
            "source": "# Mean of mean_squared_error\nprint(\"Mean of mean_squared_error\",np.mean(mean_squared_errors))\n\n# standard daviation of mean_squared_error\nprint(\"Standard Deviation of mean_squared_error\",np.std(mean_squared_errors))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# B.  Normalize the data"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.476712</td>\n      <td>-0.856472</td>\n      <td>-0.846733</td>\n      <td>-0.916319</td>\n      <td>-0.620147</td>\n      <td>0.862735</td>\n      <td>-1.217079</td>\n      <td>-0.279597</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.476712</td>\n      <td>-0.856472</td>\n      <td>-0.846733</td>\n      <td>-0.916319</td>\n      <td>-0.620147</td>\n      <td>1.055651</td>\n      <td>-1.217079</td>\n      <td>-0.279597</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.491187</td>\n      <td>0.795140</td>\n      <td>-0.846733</td>\n      <td>2.174405</td>\n      <td>-1.038638</td>\n      <td>-0.526262</td>\n      <td>-2.239829</td>\n      <td>3.551340</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.491187</td>\n      <td>0.795140</td>\n      <td>-0.846733</td>\n      <td>2.174405</td>\n      <td>-1.038638</td>\n      <td>-0.526262</td>\n      <td>-2.239829</td>\n      <td>5.055221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.790075</td>\n      <td>0.678079</td>\n      <td>-0.846733</td>\n      <td>0.488555</td>\n      <td>-1.038638</td>\n      <td>0.070492</td>\n      <td>0.647569</td>\n      <td>4.976069</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n\n   Coarse Aggregate  Fine Aggregate       Age  \n0          0.862735       -1.217079 -0.279597  \n1          1.055651       -1.217079 -0.279597  \n2         -0.526262       -2.239829  3.551340  \n3         -0.526262       -2.239829  5.055221  \n4          0.070492        0.647569  4.976069  "
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Normalize the feature data by substracting the mean and dividing by the standard deviation\nX_norm = (X - X.mean()) / X.std()\nX_norm.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": "# no. of normalize features columns = input shape\nn_cols = X_norm.shape[1]"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": "'''Building the model with 1 hidden layers containing 10 nodes with \nReLU activation and compile with adam optimizer and mean squared error loss function'''\nmodel = tf.keras.models.Sequential([\n\n    # 10 neuron hidden layer\n    tf.keras.layers.Dense(10, activation='relu',input_shape=(n_cols,)),\n    # Only 1 output neuron.\n    tf.keras.layers.Dense(1)\n])\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "#1 mean squared error is 352.0780334472656\n#2 mean squared error is 188.66046142578125\n#3 mean squared error is 142.20489501953125\n#4 mean squared error is 106.27409362792969\n#5 mean squared error is 83.33047485351562\n#6 mean squared error is 70.05797576904297\n#7 mean squared error is 63.00450134277344\n#8 mean squared error is 59.0140266418457\n#9 mean squared error is 56.065608978271484\n#10 mean squared error is 53.67483901977539\n#11 mean squared error is 51.8801383972168\n#12 mean squared error is 50.173377990722656\n#13 mean squared error is 48.885459899902344\n#14 mean squared error is 47.93967056274414\n#15 mean squared error is 46.94619369506836\n#16 mean squared error is 45.79478454589844\n#17 mean squared error is 45.05446243286133\n#18 mean squared error is 44.65903854370117\n#19 mean squared error is 43.85382080078125\n#20 mean squared error is 43.46644973754883\n#21 mean squared error is 43.19561767578125\n#22 mean squared error is 43.362728118896484\n#23 mean squared error is 43.15675735473633\n#24 mean squared error is 43.09043884277344\n#25 mean squared error is 42.82906723022461\n#26 mean squared error is 43.91071319580078\n#27 mean squared error is 44.11019515991211\n#28 mean squared error is 43.92369842529297\n#29 mean squared error is 43.70379638671875\n#30 mean squared error is 43.863407135009766\n#31 mean squared error is 43.94921112060547\n#32 mean squared error is 43.76301956176758\n#33 mean squared error is 43.853782653808594\n#34 mean squared error is 43.722869873046875\n#35 mean squared error is 43.58854293823242\n#36 mean squared error is 43.419498443603516\n#37 mean squared error is 43.36721420288086\n#38 mean squared error is 43.256126403808594\n#39 mean squared error is 43.15392303466797\n#40 mean squared error is 43.11841583251953\n#41 mean squared error is 43.137481689453125\n#42 mean squared error is 43.09935760498047\n#43 mean squared error is 43.063480377197266\n#44 mean squared error is 43.20717239379883\n#45 mean squared error is 42.883758544921875\n#46 mean squared error is 43.14277267456055\n#47 mean squared error is 43.11537170410156\n#48 mean squared error is 43.21366882324219\n#49 mean squared error is 43.41565704345703\n#50 mean squared error is 43.33526611328125\n"
                }
            ],
            "source": "# Training the model with 70% of training data for 50 epochs\nmean_squared_errors = []\ni=0\nwhile i<50: \n    from sklearn.model_selection import train_test_split\n    X_train,X_test,y_train,y_test = train_test_split(X_norm,y,test_size=0.3,random_state=1)\n\n    hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0)\n    # mean_squared_error = last value in the history\n    mean_squared_error = hist.history['val_loss'][-1]\n    mean_squared_errors.append(mean_squared_error)\n    print(f\"#{i+1} mean squared error is {mean_squared_errors[i]}\")\n    i+=1"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Mean of mean_squared_error 58.8994263458252\nStandard Deviation of mean_squared_error 49.29113524702969\n"
                }
            ],
            "source": "# Mean of mean_squared_error\nprint(\"Mean of mean_squared_error\",np.mean(mean_squared_errors))\n\n# standard daviation of mean_squared_error\nprint(\"Standard Deviation of mean_squared_error\",np.std(mean_squared_errors))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### The mean squared error in case of B is greater than A. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# C. Increase the number of epochs"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "#1 mean squared error is 548871.25\n#2 mean squared error is 44199.61328125\n#3 mean squared error is 4667.89501953125\n#4 mean squared error is 687.1221313476562\n#5 mean squared error is 236.61538696289062\n#6 mean squared error is 188.21157836914062\n#7 mean squared error is 198.4850616455078\n#8 mean squared error is 198.6468505859375\n#9 mean squared error is 183.2135467529297\n#10 mean squared error is 174.65869140625\n#11 mean squared error is 164.7347869873047\n#12 mean squared error is 173.63796997070312\n#13 mean squared error is 170.30874633789062\n#14 mean squared error is 169.2948455810547\n#15 mean squared error is 157.70169067382812\n#16 mean squared error is 206.5330047607422\n#17 mean squared error is 158.2513885498047\n#18 mean squared error is 286.57403564453125\n#19 mean squared error is 159.1696319580078\n#20 mean squared error is 167.07969665527344\n#21 mean squared error is 182.7554473876953\n#22 mean squared error is 164.34437561035156\n#23 mean squared error is 159.13233947753906\n#24 mean squared error is 148.3970947265625\n#25 mean squared error is 158.35073852539062\n#26 mean squared error is 145.61190795898438\n#27 mean squared error is 157.31924438476562\n#28 mean squared error is 210.15780639648438\n#29 mean squared error is 151.06146240234375\n#30 mean squared error is 146.45797729492188\n#31 mean squared error is 139.2804718017578\n#32 mean squared error is 140.24583435058594\n#33 mean squared error is 138.09889221191406\n#34 mean squared error is 142.94003295898438\n#35 mean squared error is 135.20989990234375\n#36 mean squared error is 134.30535888671875\n#37 mean squared error is 136.44686889648438\n#38 mean squared error is 182.1890106201172\n#39 mean squared error is 136.46580505371094\n#40 mean squared error is 134.33839416503906\n#41 mean squared error is 163.538818359375\n#42 mean squared error is 131.30148315429688\n#43 mean squared error is 150.61526489257812\n#44 mean squared error is 130.9811248779297\n#45 mean squared error is 128.5606689453125\n#46 mean squared error is 213.75247192382812\n#47 mean squared error is 142.11911010742188\n#48 mean squared error is 127.96068572998047\n#49 mean squared error is 127.26427459716797\n#50 mean squared error is 128.92791748046875\n"
                }
            ],
            "source": "#  Training the model with 70% of training data for 100 epochs\nmean_squared_errors = []\ni=0\nwhile i<50: \n    from sklearn.model_selection import train_test_split\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n\n    hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n    # mean_squared_error = last value in the history\n    mean_squared_error = hist.history['val_loss'][-1]\n    mean_squared_errors.append(mean_squared_error)\n    print(f\"#{i+1} mean squared error is {mean_squared_errors[i]}\")\n    i+=1"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Mean of mean_squared_error 12118.142562561035\nStandard Deviation of mean_squared_error 76927.7986911319\n"
                }
            ],
            "source": "# Mean of mean_squared_error\nprint(\"Mean of mean_squared_error\",np.mean(mean_squared_errors))\n\n# standard daviation of mean_squared_error\nprint(\"Standard Deviation of mean_squared_error\",np.std(mean_squared_errors))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### The mean squared error in C is very large as compared to B . This implies that more epochs will not help without the additional hidden layers."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# D. Increase the number of hidden layers"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": "'''Building the model with 3 hidden layers containing 10 nodes with \nReLU activation and compile with adam optimizer and mean squared error loss function'''\nmodel = tf.keras.models.Sequential([\n\n    # 10 neuron hidden layer\n    tf.keras.layers.Dense(10, activation='relu',input_shape=(n_cols,)),\n    tf.keras.layers.Dense(10, activation='relu'),\n    tf.keras.layers.Dense(10, activation='relu'),\n    # Only 1 output neuron.\n    tf.keras.layers.Dense(1)\n])\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')"
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "#1 mean squared error is 116.83686065673828\n#2 mean squared error is 87.96060943603516\n#3 mean squared error is 68.04264068603516\n#4 mean squared error is 62.599098205566406\n#5 mean squared error is 59.56043243408203\n#6 mean squared error is 55.86803436279297\n#7 mean squared error is 54.970638275146484\n#8 mean squared error is 52.91413116455078\n#9 mean squared error is 54.48128890991211\n#10 mean squared error is 52.76626205444336\n#11 mean squared error is 53.61362075805664\n#12 mean squared error is 53.14083480834961\n#13 mean squared error is 54.251163482666016\n#14 mean squared error is 52.33160400390625\n#15 mean squared error is 52.99692153930664\n#16 mean squared error is 54.72600555419922\n#17 mean squared error is 53.22069549560547\n#18 mean squared error is 52.07146072387695\n#19 mean squared error is 51.5761604309082\n#20 mean squared error is 52.03870391845703\n#21 mean squared error is 50.868858337402344\n#22 mean squared error is 51.590057373046875\n#23 mean squared error is 51.453182220458984\n#24 mean squared error is 51.49149703979492\n#25 mean squared error is 56.0167121887207\n#26 mean squared error is 52.20735549926758\n#27 mean squared error is 51.51958084106445\n#28 mean squared error is 51.851680755615234\n#29 mean squared error is 51.632354736328125\n#30 mean squared error is 52.765037536621094\n#31 mean squared error is 50.884647369384766\n#32 mean squared error is 50.87373733520508\n#33 mean squared error is 52.690643310546875\n#34 mean squared error is 51.20969772338867\n#35 mean squared error is 52.90763854980469\n#36 mean squared error is 52.89227294921875\n#37 mean squared error is 50.67923355102539\n#38 mean squared error is 52.22008514404297\n#39 mean squared error is 52.462547302246094\n#40 mean squared error is 50.945892333984375\n#41 mean squared error is 50.56090545654297\n#42 mean squared error is 52.7591552734375\n#43 mean squared error is 50.865962982177734\n#44 mean squared error is 50.19270706176758\n#45 mean squared error is 50.16273498535156\n#46 mean squared error is 50.740299224853516\n#47 mean squared error is 50.936092376708984\n#48 mean squared error is 55.240570068359375\n#49 mean squared error is 49.8414192199707\n#50 mean squared error is 49.512481689453125\n"
                }
            ],
            "source": "# Training the model with 70% of training data for 50 epochs\nmean_squared_errors = []\ni=0\nwhile i<50: \n    from sklearn.model_selection import train_test_split\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n\n    hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, verbose=0)\n    # mean_squared_error = last value in the history\n    mean_squared_error = hist.history['val_loss'][-1]\n    mean_squared_errors.append(mean_squared_error)\n    print(f\"#{i+1} mean squared error is {mean_squared_errors[i]}\")\n    i+=1"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Mean of mean_squared_error 54.91884414672852\nStandard Deviation of mean_squared_error 10.592987034100332\n"
                }
            ],
            "source": "# Mean of mean_squared_error\nprint(\"Mean of mean_squared_error\",np.mean(mean_squared_errors))\n\n# standard daviation of mean_squared_error\nprint(\"Standard Deviation of mean_squared_error\",np.std(mean_squared_errors))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Compared to B it has less mean squared error. This proves the importance of more hidden layers as compared with other parameters."
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}